# BERT Model Optimization Project

This repository contains a lightweight transformer model that was optimized using **dynamic quantization** for faster inference and reduced model size.

##  What We Did

- Loaded a small BERT-based model from Hugging Face ðŸ¤—
- Applied **dynamic quantization** using PyTorch
- Measured model size and inference time before & after optimization
- Ideal for real-time NLP applications on resource-limited devices (e.g. laptops with small GPUs)

